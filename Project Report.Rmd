---
title: "Diminishing Self-Prioritization: Enhancing Social Perception through Reverse Matching Training"
author: "Xunqing Zheng & Chenghao Zhou"
output: pdf_document
---

## Introduction
In social interactions, individuals often navigate a complex landscape of interpersonal dynamics.
Human cognition is inherently biased towards prioritizing one's own interests and viewpoints, potentially hindering the capacity for empathetic and socially attuned behavior.
This phenomenon, known as self-prioritization, which has significant implications for the quality of interpersonal relationships, cooperation, and societal harmony.
Reverse Matching Training targets the underlying biases associated with self-prioritization directly and aims to reorient individuals' cognitive processes towards a more equitable consideration of others' perspectives.

In this longitudinal cognitive intervention experiment, fourteen participants were divided into two groups based on their task prioritization: match-priority and mismatch-priority.
Initially, they learned to link specific shapes - circles and squares - with textual labels, including "self," "other," and two visually similar Chinese characters.
During the testing phase, participants responded to a visual cue - a fixation cross for 500-800 ms - followed by simultaneous presentation of a shape and text.
They had to quickly decide if the combination was a match or mismatch based on their initial training, using specific keys for each condition. The match-priority group was instructed to press one key if the items matched and another if they did not match or if it was a filler item.
Conversely, the mismatch-priority group was to press one key for mismatches and another for matches or fillers.
This was followed by a 1200 ms blank screen and a 1500 ms relaxation period. The display used was a 1024x768 CRT monitor refreshing at 85Hz.
Assessments were made at baseline, across seven training sessions, and during a formal experimental phase.

## Initial Project Proposal

This project analysis is aiming to understand the data from a Bayesian approach to answer following questions.

1.  Does task prioritization affect reaction and accuracy in cognitive matching tasks?

2.  Are there observable changes in EEG patterns related to task accuracy?

3.  Do participants improve in task performance over repeated sessions?

Initially, we were thinking about analyzing the data with Bayesian binomial model to estimate the accuracy/reaction time for each group, than apply Bayesian multivariate analysis to correlate EEG data (frequency bands, amplitude, etc.) with task performance (correct/incorrect).

However, after lengthy discussion and examining the available raw data, we decided to focus this analysis project on participant's reaction time and to understand its improvement after training.
What's worth calling out is that for the simplicity of this project, we did not include the accuracy in this analysis

## Attribution

## Packages
```{r library, eval=TRUE, message=FALSE, warning=FALSE, include=TRUE}
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(brms)
library(emmeans)
library(loo)
library(rstanarm)
```


## Raw Data Summary
The first step into the analysis is data cleaning, which we first converted the average reaction time from seconds to milliseconds as most of this types of analysis were done in milliseconds.
In addition to that, we also make sure all the necessary conditions are clearly identified in the data, such as if the specific row is associated with "Fill", "Match", or "Mismatch" experiment session, and if the session is self related or not.
An intersection condition column is created based on these conditions: 1 = Fill Self, 2 = Mismatch Self, 3 = Match Self, 4 = Fill Non-Self, 5 = Mismatch Non-Self, 6 = Match Non-Self.
Lastly, we filtered data to only focused on only the reaction time at Baseline and the Formal tests, removing all the training sections in between.
```{r dataset, echo=TRUE, message=FALSE, warning=FALSE}
#clean data
RawRT = read_csv("RawRT.csv")
#data <- read_csv("UsefulData05122024.csv")

#filtered_data <- data %>%
filtered_data <- RawRT %>%
  mutate(
    meanRT = meanRT * 1000,  # Convert to milliseconds
    session = factor(session, levels = c(1:9), labels = c("Baseline", 'TR1', 'TR2', 'TR3', 'TR4', 'TR5', 'TR6', 'TR7', "Formal")),
    group = factor(group, levels = c(1, 2), labels = c("Match First", "Mismatch First")),
    type = case_when(
      conds %in% c(1, 4) ~ "Fill",
      conds %in% c(3, 6) ~ "Match",
      conds %in% c(2, 5) ~ "Mismatch"
    ),
    ifself_related = case_when(
      conds %in% c(1, 2, 3) ~ "Self",
      conds %in% c(4, 5, 6) ~ "Non-Self"
    ),
    type = factor(type),
    ifself_related = factor(ifself_related),
    gender = factor(gender)  # Ensure gender is treated as a categorical variable
  ) %>%
  filter(session %in% c("Baseline", "Formal"))
```

With all data ready, we first take a look at the density distribution of the average reaction time for self-related trials and non-self related trials across the Baseline and Formal experimental sessions. Overall the reaction time data follows roughly a normal distribution with Baseline skewing slightly to the left and formal slightly skewing to the right. We also observed a slightly stronger variations at the Baseline and less variations in distributions during the Formal sessions.
```{r}
p = ggplot(filtered_data, aes(x=meanRT, color=ifself_related)) + 
  geom_density() +
  facet_grid(cols = vars(session)) +
  theme_minimal() +
  labs(
    title = "Density Distribution of Reaction Time between Baseline and Formal Session",
    x = "Reaction Time (ms)",
    y = "Frequency",
    color = "Self-Relatedness"
  )

p
```

By looking at the box plot for reaction time between "Baseline" and "Formal", interestingly, we observed improvements across all experiment conditions after the training sessions. However, it is still a bit hard to tell if there is a difference in the improvement in reaction times across by self-relatedness.
```{r Boxplot, echo=TRUE}
plot_RT <- ggplot(filtered_data, aes(x = type, y = meanRT, fill = ifself_related)) +
  geom_boxplot(outlier.shape = NA) +  # Hide outliers to clean up the plot
  geom_jitter(width = 0.1, height = 0, size = 1, alpha = 0.5, color = "black") +  
  # Add jitter to show data spread
  facet_grid(group ~ session, scales = "free_x") +  
  # Allow each facet to have its own x-axis scale
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),  
    # Rotate x-axis labels to avoid overlap
    strip.text.x = element_text(size = 8),  # Smaller facet labels if needed
    strip.text.y = element_text(size = 8),
    axis.title = element_text(size = 12),  # Larger axis titles
    plot.title = element_text(size = 14, face = "bold")# Bolder and bigger title
  ) +
  labs(
    title = "Reaction Time between Baseline and Formal Session",
    x = "Type",
    y = "Reaction Time (ms)",
    fill = "Self-Relatedness"
  )

plot_RT
```

Before exploring the modeling route, let's take a look at one more plot, taking a look at the relationship between baseline and formal under each experiment conditions. Interestingly, we did not observe a stronger improvement for non-self related reaction time when compared to the self related. For the mismatch first subgroup, we actually observed a longer reaction time after all the trainings.
```{r message=FALSE, warning=FALSE}
filtered_data_2 = filtered_data %>% 
  select(-acc_c,-acc_all) %>% 
  pivot_wider(names_from = session, values_from = meanRT)

p = ggplot(filtered_data_2, aes(x=Baseline, y=Formal, color = ifself_related)) + 
  geom_point(outlier.shape = NA) +
  geom_smooth(method=lm, se=FALSE)+
  facet_grid(group ~ type)+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

p
```

## Prior Predictive Simulation
To simulate
## Model Fitting, PPCs, & Model Selection

## Discussion
